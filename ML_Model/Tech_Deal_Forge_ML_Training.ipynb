{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24ed0e7",
   "metadata": {},
   "source": [
    "# üî® Tech Deal Forge - ML Training Notebook\n",
    "\n",
    "**Google Colab ML Training Script for Deal Quality Prediction**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Workflow\n",
    "\n",
    "1. ‚úÖ **Upload to Google Colab** - Open this notebook in Colab\n",
    "2. ‚úÖ **Upload CSV file** - Export from `deals.db` using `export_deals_for_ml.py`\n",
    "3. ‚úÖ **Run all cells** - Execute the entire notebook\n",
    "4. ‚úÖ **Download trained model** - Get the `.joblib` file\n",
    "5. ‚úÖ **Deploy to Streamlit** - Place model in project folder\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What This Notebook Does\n",
    "\n",
    "- Loads deals data from CSV (exported from SQLite database)\n",
    "- Engineers features (website encoding, categories, temporal)\n",
    "- Creates target variable (deal quality score 0-100)\n",
    "- Trains Random Forest model\n",
    "- Evaluates performance (R¬≤, RMSE, MAE)\n",
    "- Visualizes feature importance\n",
    "- Exports trained model for Streamlit dashboard\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Tech Deal Forge  \n",
    "**Date:** November 2024  \n",
    "**Model Type:** Random Forest Regressor  \n",
    "**Purpose:** Predict deal quality based on discount, rating, reviews, and other features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff105ba6",
   "metadata": {},
   "source": [
    "## üì§ Step 1: Upload CSV Data\n",
    "\n",
    "Upload your deals CSV file exported from the database.\n",
    "\n",
    "**To generate this CSV locally:**\n",
    "```bash\n",
    "python export_deals_for_ml.py\n",
    "```\n",
    "\n",
    "This creates: `output/ml_training_data_YYYYMMDD_HHMMSS.csv`\n",
    "\n",
    "**Upload that file here ‚¨áÔ∏è**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üî® TECH DEAL FORGE - ML MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüì§ Upload your deals CSV file:\")\n",
    "print(\"   (Look for 'ml_training_data_*.csv' in your output folder)\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    raise ValueError(\"‚ùå No file uploaded! Please upload a CSV file.\")\n",
    "\n",
    "filename = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {filename}\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(filename)\n",
    "print(f\"‚úÖ Loaded {len(df):,} deals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c0cfa",
   "metadata": {},
   "source": [
    "## üìä Step 2: Data Quality Report\n",
    "\n",
    "Check the data before training to ensure it's complete and valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f98b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä DATA QUALITY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìà Dataset Overview:\")\n",
    "print(f\"   - Total rows: {len(df):,}\")\n",
    "print(f\"   - Columns: {len(df.columns)}\")\n",
    "print(f\"   - Date range: {df['scraped_at'].min()} ‚Üí {df['scraped_at'].max()}\")\n",
    "print(f\"   - Websites: {', '.join(df['website'].value_counts().index.tolist())}\")\n",
    "print(f\"   - Categories: {df['category'].nunique()} unique\")\n",
    "\n",
    "print(f\"\\nüí∞ Price Statistics:\")\n",
    "df['price_numeric'] = pd.to_numeric(df['price_numeric'], errors='coerce')\n",
    "valid_prices = df['price_numeric'].dropna()\n",
    "if len(valid_prices) > 0:\n",
    "    print(f\"   - Min price: ${valid_prices.min():.2f}\")\n",
    "    print(f\"   - Max price: ${valid_prices.max():.2f}\")\n",
    "    print(f\"   - Avg price: ${valid_prices.mean():.2f}\")\n",
    "    print(f\"   - Median price: ${valid_prices.median():.2f}\")\n",
    "\n",
    "print(f\"\\nüî¢ Data Completeness:\")\n",
    "critical_cols = ['price_numeric', 'discount_percent', 'rating', 'reviews_count', 'category', 'website']\n",
    "for col in critical_cols:\n",
    "    if col in df.columns:\n",
    "        missing = df[col].isna().sum()\n",
    "        pct = (missing / len(df)) * 100\n",
    "        status = \"‚úÖ\" if pct < 20 else \"‚ö†Ô∏è\" if pct < 50 else \"‚ùå\"\n",
    "        print(f\"   {status} {col}: {pct:.1f}% missing ({missing:,} rows)\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nüìã Sample Data (first 5 rows):\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d0a8f",
   "metadata": {},
   "source": [
    "## üîß Step 3: Feature Engineering\n",
    "\n",
    "Prepare features that match your `ml_integration.py` structure:\n",
    "- Clean numeric columns\n",
    "- Encode websites (one-hot)\n",
    "- Encode categories (multi-label)\n",
    "- Create temporal features\n",
    "- Generate target variable (deal quality score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(df):\n",
    "    \"\"\"\n",
    "    Prepare features matching ml_integration.py\n",
    "    This ensures compatibility with your Streamlit dashboard\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean numeric columns\n",
    "    df['price_numeric'] = pd.to_numeric(df['price_numeric'], errors='coerce')\n",
    "    df['discount_percent'] = pd.to_numeric(df['discount_percent'], errors='coerce').fillna(0)\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce').fillna(0)\n",
    "    df['reviews_count'] = pd.to_numeric(df['reviews_count'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Website encoding (one-hot)\n",
    "    df['website_bestbuy'] = (df['website'] == 'bestbuy').astype(int)\n",
    "    df['website_slickdeals'] = (df['website'] == 'slickdeals').astype(int)\n",
    "    df['website_newegg'] = (df['website'] == 'newegg').astype(int)\n",
    "    \n",
    "    # Category encoding (multi-label possible)\n",
    "    df['category_gaming'] = df['category'].str.contains('gaming|game', case=False, na=False).astype(int)\n",
    "    df['category_laptop'] = df['category'].str.contains('laptop|notebook', case=False, na=False).astype(int)\n",
    "    df['category_monitor'] = df['category'].str.contains('monitor|display', case=False, na=False).astype(int)\n",
    "    df['category_electronics'] = df['category'].str.contains('electronics|tech', case=False, na=False).astype(int)\n",
    "    \n",
    "    # Temporal features\n",
    "    df['scraped_at'] = pd.to_datetime(df['scraped_at'])\n",
    "    df['day_of_week'] = df['scraped_at'].dt.dayofweek\n",
    "    df['month'] = df['scraped_at'].dt.month\n",
    "    df['is_weekend'] = (df['scraped_at'].dt.dayofweek >= 5).astype(int)\n",
    "    \n",
    "    # Historical features (simplified - no lookback for training)\n",
    "    df['price_vs_avg'] = 1.0\n",
    "    df['price_vs_min'] = 1.0\n",
    "    df['times_seen'] = 1\n",
    "    df['price_std'] = 0.0\n",
    "    df['recent_trend'] = 0.0\n",
    "    \n",
    "    # CREATE TARGET: Deal Quality Score (0-100)\n",
    "    max_discount = df['discount_percent'].max() if df['discount_percent'].max() > 0 else 1\n",
    "    \n",
    "    df['deal_quality_score'] = (\n",
    "        (df['discount_percent'] / max_discount * 40) +  # 40% weight on discount\n",
    "        (df['rating'] / 5.0 * 30) +                     # 30% weight on rating\n",
    "        (np.clip(df['reviews_count'], 0, 100) / 100 * 30)  # 30% weight on reviews\n",
    "    )\n",
    "    \n",
    "    # Fill missing scores with median\n",
    "    median_score = df['deal_quality_score'].median()\n",
    "    df['deal_quality_score'] = df['deal_quality_score'].fillna(median_score)\n",
    "    \n",
    "    # CRITICAL: Feature list MUST match ml_integration.py prepare_features()\n",
    "    feature_cols = [\n",
    "        'price_numeric', 'discount_percent', 'rating', 'reviews_count',\n",
    "        'website_bestbuy', 'website_slickdeals',\n",
    "        'category_gaming', 'category_laptop', 'category_monitor',\n",
    "        'day_of_week', 'month', 'is_weekend',\n",
    "        'price_vs_avg', 'price_vs_min', 'times_seen', 'price_std', 'recent_trend'\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_cols].fillna(0)\n",
    "    y = df['deal_quality_score']\n",
    "    \n",
    "    # Remove any rows with NaN in target\n",
    "    valid_idx = ~y.isna()\n",
    "    X = X[valid_idx]\n",
    "    y = y[valid_idx]\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "# Prepare features\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîß FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X, y, feature_names = prepare_training_data(df)\n",
    "\n",
    "print(f\"\\n‚úÖ Training data prepared:\")\n",
    "print(f\"   - Samples: {X.shape[0]:,} deals\")\n",
    "print(f\"   - Features: {X.shape[1]}\")\n",
    "print(f\"   - Target range: {y.min():.1f} - {y.max():.1f}\")\n",
    "print(f\"\\nüìã Features used:\")\n",
    "for i, feat in enumerate(feature_names, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a43176",
   "metadata": {},
   "source": [
    "## ü§ñ Step 4: Train Model\n",
    "\n",
    "Train a Random Forest Regressor to predict deal quality scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Split data (80/20 train/test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ü§ñ MODEL TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset split:\")\n",
    "print(f\"   - Training: {len(X_train):,} deals ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   - Testing: {len(X_test):,} deals ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Train Random Forest\n",
    "print(f\"\\nüå≤ Training Random Forest Regressor...\")\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=10,          # Prevent overfitting\n",
    "    min_samples_split=5,   # Require at least 5 samples to split\n",
    "    random_state=42,       # Reproducibility\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"‚úÖ Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20011469",
   "metadata": {},
   "source": [
    "## üìà Step 5: Evaluate Performance\n",
    "\n",
    "Check how well the model performs on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà MODEL PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nüéØ Training Set Performance:\")\n",
    "print(f\"   - R¬≤ Score: {r2_train:.3f}\")\n",
    "\n",
    "print(f\"\\nüéØ Test Set Performance:\")\n",
    "print(f\"   - R¬≤ Score: {r2_test:.3f} (higher is better, max 1.0)\")\n",
    "print(f\"   - RMSE: {rmse_test:.2f} points\")\n",
    "print(f\"   - MAE: {mae_test:.2f} points (avg error)\")\n",
    "\n",
    "# Interpretation\n",
    "if r2_test > 0.7:\n",
    "    print(f\"\\n‚úÖ EXCELLENT - Model explains {r2_test*100:.1f}% of variance\")\n",
    "elif r2_test > 0.5:\n",
    "    print(f\"\\n‚úÖ GOOD - Model explains {r2_test*100:.1f}% of variance\")\n",
    "elif r2_test > 0.3:\n",
    "    print(f\"\\n‚ö†Ô∏è  FAIR - Model explains {r2_test*100:.1f}% of variance\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  LIMITED - Model explains only {r2_test*100:.1f}% of variance\")\n",
    "    print(f\"   Consider collecting more diverse data or adding features\")\n",
    "\n",
    "# Check for overfitting\n",
    "if r2_train - r2_test > 0.2:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Possible overfitting detected\")\n",
    "    print(f\"   Training R¬≤: {r2_train:.3f} | Test R¬≤: {r2_test:.3f}\")\n",
    "    print(f\"   Consider: more data, simpler model, or regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe481c",
   "metadata": {},
   "source": [
    "## üîç Step 6: Feature Importance\n",
    "\n",
    "See which features matter most for predicting deal quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83800592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä Top Features (what matters most):\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(importance_df['feature'][:10], importance_df['importance'][:10])\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.title('Top 10 Most Important Features for Deal Quality Prediction', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21484acd",
   "metadata": {},
   "source": [
    "## üéØ Step 7: Sample Predictions\n",
    "\n",
    "Test the model on real examples to see how accurate it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ SAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test on 10 random examples\n",
    "n_samples = min(10, len(X_test))\n",
    "sample_idx = np.random.choice(len(X_test), n_samples, replace=False)\n",
    "test_samples = X_test.iloc[sample_idx]\n",
    "test_actuals = y_test.iloc[sample_idx]\n",
    "test_predictions = model.predict(test_samples)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual Score': test_actuals.values,\n",
    "    'Predicted Score': test_predictions,\n",
    "    'Difference': test_predictions - test_actuals.values,\n",
    "    'Error %': ((test_predictions - test_actuals.values) / test_actuals.values * 100)\n",
    "})\n",
    "\n",
    "print(f\"\\n{comparison.to_string(index=False)}\")\n",
    "print(f\"\\nAverage absolute error: {np.abs(comparison['Difference']).mean():.2f} points\")\n",
    "\n",
    "# Visual comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.5, s=20)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Deal Quality Score', fontsize=12)\n",
    "plt.ylabel('Predicted Deal Quality Score', fontsize=12)\n",
    "plt.title('Predicted vs Actual Deal Quality Scores', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7c196",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Save and Download Model\n",
    "\n",
    "Export the trained model to use in your Streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8313ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üíæ SAVING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "model_filename = f\"deal_predictor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.joblib\"\n",
    "\n",
    "# Save model with metadata\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'feature_names': feature_names,\n",
    "    'r2_score': r2_test,\n",
    "    'rmse': rmse_test,\n",
    "    'mae': mae_test,\n",
    "    'trained_on': datetime.now().isoformat(),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, model_filename)\n",
    "\n",
    "print(f\"\\n‚úÖ Model saved: {model_filename}\")\n",
    "print(f\"\\nüì¶ Model Package Contents:\")\n",
    "print(f\"   - Model: Random Forest Regressor\")\n",
    "print(f\"   - Features: {len(feature_names)}\")\n",
    "print(f\"   - R¬≤ Score: {r2_test:.3f}\")\n",
    "print(f\"   - RMSE: {rmse_test:.2f}\")\n",
    "print(f\"   - Training samples: {len(X_train):,}\")\n",
    "\n",
    "# Download the model\n",
    "print(f\"\\n‚¨áÔ∏è  Downloading model...\")\n",
    "files.download(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362688e",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Complete! Next Steps\n",
    "\n",
    "Follow these instructions to deploy your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"\\n1Ô∏è‚É£  Place downloaded model in your project root folder:\")\n",
    "print(f\"    üìÅ Senior-Project-Tech-Deal-Forge/\")\n",
    "print(f\"       ‚îî‚îÄ‚îÄ {model_filename}\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  Test locally in Streamlit:\")\n",
    "print(f\"    streamlit run streamlit_dashboard.py\")\n",
    "print(f\"    ‚Üí Go to 'ü§ñ AI Predictions' tab\")\n",
    "print(f\"    ‚Üí Enter model path: {model_filename}\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  Deploy to Streamlit Cloud:\")\n",
    "print(f\"    git add {model_filename}\")\n",
    "print(f\"    git commit -m 'Add trained ML model'\")\n",
    "print(f\"    git push origin main\")\n",
    "\n",
    "print(f\"\\nüìä Model Performance Summary:\")\n",
    "print(f\"   ‚úÖ R¬≤ Score: {r2_test:.3f}\")\n",
    "print(f\"   ‚úÖ Average error: {mae_test:.2f} points\")\n",
    "print(f\"   ‚úÖ Trained on: {len(X_train):,} deals\")\n",
    "\n",
    "print(f\"\\nüí° Tips:\")\n",
    "print(f\"   - Higher R¬≤ = better predictions (max 1.0)\")\n",
    "print(f\"   - Retrain monthly with new data for better accuracy\")\n",
    "print(f\"   - Feature importance shows what drives deal quality\")\n",
    "\n",
    "print(f\"\\nüéâ Your ML model is ready to predict deal quality!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
